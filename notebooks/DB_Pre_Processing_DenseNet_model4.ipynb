{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5adccf1c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787d6a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 15:06:23.127871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import utils, optimizers\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.applications import densenet\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from tensorflow import convert_to_tensor\n",
    "import matplotlib.image as mpimg\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbea69",
   "metadata": {},
   "source": [
    "# Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e20bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These variables can be changes, excluding train_dir\n",
    "train_dir = \"../raw_data/Training\"\n",
    "img_height, img_width = 256, 256\n",
    "batch_size = 32\n",
    "poses = sorted(os.listdir(\"../raw_data/Training\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b351c39-5ddc-4c5e-8fea-faf4513d438d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Boat_Pose_or_Paripurna_Navasana_',\n",
       " 'Bound_Angle_Pose',\n",
       " 'Bow_Pose_or_Dhanurasana_',\n",
       " 'Bridge_Pose_or_Setu_Bandha_Sarvangasana_',\n",
       " 'Camel_Pose_or_Ustrasana_',\n",
       " 'Cat_Cow_Pose_or_Marjaryasana_',\n",
       " 'Cat_Pose',\n",
       " 'Chair_Pose_or_Utkatasana_',\n",
       " 'Child_Pose',\n",
       " 'Cobra_Pose_or_Bhujangasana_',\n",
       " 'Cockerel_Pose',\n",
       " 'Corpse_Pose_or_Savasana_',\n",
       " 'Cow_Face_Pose_or_Gomukhasana_',\n",
       " 'Cow_Pose',\n",
       " 'Crane_(Crow)_Pose',\n",
       " 'Downward-Facing_Dog_pose_or_Adho_Mukha_Svanasana_',\n",
       " 'Eagle_Pose_or_Garudasana_',\n",
       " 'Eight-Angle_Pose_or_Astavakrasana_',\n",
       " 'Extended_Puppy_Pose_or_Uttana_Shishosana_',\n",
       " 'Extended_Revolved_Side_Angle_Pose_or_Utthita_Parsvakonasana_Twist',\n",
       " 'Extended_Revolved_Side_Angle_Pose_or_Utthita_Parsvakonasana_Untwist',\n",
       " 'Extended_Revolved_Triangle_Pose_or_Utthita_Trikonasana_',\n",
       " 'Feathered_Peacock_Pose_or_Pincha_Mayurasana_',\n",
       " 'Firefly_Pose_or_Tittibhasana_',\n",
       " 'Fish_Pose_or_Matsyasana_',\n",
       " 'Four-Limbed_Staff',\n",
       " 'Frog_Pose_or_Bhekasana',\n",
       " 'Garland_Pose_or_Malasana_',\n",
       " 'Gate_Pose_or_Parighasana_',\n",
       " 'Half_Lord_of_the_Fishes_Pose_or_Ardha_Matsyendrasana_',\n",
       " 'Half_Moon_Pose_or_Ardha_Chandrasana_',\n",
       " 'Handstand_pose_or_Adho_Mukha_Vrksasana_',\n",
       " 'Happy_Baby_Pose_or_Ananda_Balasana_',\n",
       " 'Head-to-Knee_Forward_Bend_pose_or_Janu_Sirsasana_',\n",
       " 'Heron_Pose_or_Krounchasana_',\n",
       " 'Intense_Side_Stretch_Pose_or_Parsvottanasana_',\n",
       " 'Legs-Up-the-Wall_Pose_or_Viparita_Karani_',\n",
       " 'Locust_Pose_or_Salabhasana_',\n",
       " 'Lotus_pose_padmasana',\n",
       " 'Low_Lunge_pose_or_Anjaneyasana_',\n",
       " 'Peacock_Pose_or_Mayurasana_',\n",
       " 'Pigeon_Pose_or_Kapotasana_',\n",
       " 'Plank_Pose_or_Kumbhakasana_',\n",
       " 'Plow_Pose_or_Halasana_',\n",
       " 'Pose_Dedicated_to_the_Sage_Koundinya_or_Eka_Pada_Koundinyanasana_I_and_II',\n",
       " 'Rajakapotasana',\n",
       " 'Reclining_Hand-to-Big-Toe_Pose_or_Supta_Padangusthasana_',\n",
       " 'Reverse_warrior_pose_or_viparita_virabhadrasana',\n",
       " 'Revolved_Head-to-Knee_Pose_or_Parivrtta_Janu_Sirsasana_',\n",
       " 'Scale_Pose_or_Tolasana_',\n",
       " 'Scorpion_pose_or_vrischikasana',\n",
       " 'Seated_Forward_Bend_pose_or_Paschimottanasana_',\n",
       " 'Shoulder-Pressing_Pose_or_Bhujapidasana_',\n",
       " 'Side-Reclining_Leg_Lift_pose_or_Anantasana_',\n",
       " 'Side_Crane_(Crow)_Pose_or_Parsva_Bakasana_',\n",
       " 'Side_Plank_Pose_or_Vasisthasana_',\n",
       " 'Sitting_pose_1_(normal)',\n",
       " 'Split_pose',\n",
       " 'Staff_Pose_',\n",
       " 'Standing_Forward_Bend_pose_or_Uttanasana_',\n",
       " 'Standing_Split_pose_or_Urdhva_Prasarita_Eka_Padasana_',\n",
       " 'Standing_big_toe_hold_pose_or_Utthita_Padangusthasana',\n",
       " 'Supported_Headstand_pose_or_Salamba_Sirsasana_',\n",
       " 'Supported_Shoulderstand_pose_or_Salamba_Sarvangasana_',\n",
       " 'Supta_Baddha_Konasana_',\n",
       " 'Supta_Virasana_Vajrasana',\n",
       " 'Tortoise_Pose',\n",
       " 'Tree_Pose_or_Vrksasana_',\n",
       " 'Two_legged_inverted_staff_pose_or_dwi_pada_viparita_dandasana',\n",
       " 'Upward_Bow_(Wheel)_Pose_or_Urdhva_Dhanurasana_',\n",
       " 'Upward_Facing_Two-Foot_Staff_Pose_or_Dwi_Pada_Viparita_Dandasana_',\n",
       " 'Upward_Plank_Pose_or_Purvottanasana_',\n",
       " 'Upward_facing_dog_urdhva_mukha_svanasana',\n",
       " 'Virasana_or_Vajrasana',\n",
       " 'Warrior_III_Pose_or_Virabhadrasana_III_',\n",
       " 'Warrior_II_Pose_or_Virabhadrasana_II_',\n",
       " 'Warrior_I_Pose_or_Virabhadrasana_I_',\n",
       " 'Wide-Angle_Seated_Forward_Bend_pose_or_Upavistha_Konasana_',\n",
       " 'Wide-Legged_Forward_Bend_pose_or_Prasarita_Padottanasana_',\n",
       " 'Wild_Thing_pose_or_Camatkarasana_',\n",
       " 'Wind_Relieving_pose_or_Pawanmuktasana',\n",
       " 'Yogic_sleep_pose_or_Yoganidrasana']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11510 images belonging to 83 classes.\n",
      "Found 2837 images belonging to 83 classes.\n"
     ]
    }
   ],
   "source": [
    "#Splits into train_generator and validation_generator\n",
    "#This bulk uploads the images\n",
    "#Creates target (y) for us!\n",
    "\n",
    "#Play around with the interpolation argument - bicubic, lanczos??? \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    vertical_flip=True,\n",
    "                                    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                    train_dir,\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    subset='training',\n",
    "                                    keep_aspect_ratio=True,\n",
    "                                    interpolation='lanczos') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                                    train_dir, # same directory as training data\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    subset='validation',\n",
    "                                    keep_aspect_ratio=True,\n",
    "                                    interpolation='lanczos') # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f530f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4675f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# Model needs building + transfer learning  \n",
    "...\n",
    "def initialize_model():\n",
    "    base_model = densenet.DenseNet169(\n",
    "                        include_top=False,\n",
    "                        weights='imagenet',\n",
    "                        input_shape=(img_height, img_width, 3),\n",
    "                        classifier_activation='softmax')\n",
    "    \n",
    "    base_model.trainable = True\n",
    "\n",
    "    model = models.Sequential([ \n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1000,activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(900, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(800, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(700, activation=\"relu\"),\n",
    "        layers.Dense(83, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb61e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 15:06:48.464958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:50.260589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:50.262723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:50.285159: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 15:06:50.298918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:50.300884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:50.302676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:57.796556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:57.798706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:57.800578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 15:06:57.802321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13576 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63383da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet169 (Functional)    (None, 8, 8, 1664)        12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 106496)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 106496)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              106497000 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 900)               900900    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 900)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 800)               720800    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 700)               560700    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 83)                58183     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,380,463\n",
      "Trainable params: 121,222,063\n",
      "Non-trainable params: 158,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d35456",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6636f75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 15:07:57.218402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2023-03-13 15:08:13.688554: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55b4fd5e76c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-13 15:08:13.688607: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-03-13 15:08:14.220284: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-13 15:08:15.547364: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/359 [..............................] - ETA: 5:45 - loss: 5.1488 - accuracy: 0.0312    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3106/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - ETA: 0s - loss: 4.2962 - accuracy: 0.0473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3106/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 700s 2s/step - loss: 4.2962 - accuracy: 0.0473 - val_loss: 3.7282 - val_accuracy: 0.1026\n",
      "Epoch 2/500\n",
      "359/359 [==============================] - 299s 832ms/step - loss: 3.4490 - accuracy: 0.1396 - val_loss: 2.8877 - val_accuracy: 0.2447\n",
      "Epoch 3/500\n",
      "359/359 [==============================] - 300s 835ms/step - loss: 2.6795 - accuracy: 0.2705 - val_loss: 2.1154 - val_accuracy: 0.4226\n",
      "Epoch 4/500\n",
      "359/359 [==============================] - 299s 832ms/step - loss: 2.1334 - accuracy: 0.3986 - val_loss: 1.7943 - val_accuracy: 0.4925\n",
      "Epoch 5/500\n",
      "359/359 [==============================] - 300s 835ms/step - loss: 1.7428 - accuracy: 0.4916 - val_loss: 1.6124 - val_accuracy: 0.5550\n",
      "Epoch 6/500\n",
      "359/359 [==============================] - 299s 833ms/step - loss: 1.5179 - accuracy: 0.5519 - val_loss: 1.4188 - val_accuracy: 0.6048\n",
      "Epoch 7/500\n",
      "359/359 [==============================] - 299s 832ms/step - loss: 1.3277 - accuracy: 0.6036 - val_loss: 1.3085 - val_accuracy: 0.6254\n",
      "Epoch 8/500\n",
      "359/359 [==============================] - 302s 840ms/step - loss: 1.1620 - accuracy: 0.6474 - val_loss: 1.2593 - val_accuracy: 0.6538\n",
      "Epoch 9/500\n",
      "359/359 [==============================] - 299s 833ms/step - loss: 1.0123 - accuracy: 0.6931 - val_loss: 1.1214 - val_accuracy: 0.6939\n",
      "Epoch 10/500\n",
      "359/359 [==============================] - 303s 844ms/step - loss: 0.9261 - accuracy: 0.7164 - val_loss: 1.0937 - val_accuracy: 0.7099\n",
      "Epoch 11/500\n",
      "359/359 [==============================] - 300s 834ms/step - loss: 0.8351 - accuracy: 0.7431 - val_loss: 1.1734 - val_accuracy: 0.6928\n",
      "Epoch 12/500\n",
      "359/359 [==============================] - 301s 840ms/step - loss: 0.7563 - accuracy: 0.7715 - val_loss: 1.0992 - val_accuracy: 0.7113\n",
      "Epoch 13/500\n",
      "359/359 [==============================] - 302s 842ms/step - loss: 0.7001 - accuracy: 0.7883 - val_loss: 1.0632 - val_accuracy: 0.7269\n",
      "Epoch 14/500\n",
      "359/359 [==============================] - 303s 843ms/step - loss: 0.6633 - accuracy: 0.7984 - val_loss: 1.0916 - val_accuracy: 0.7315\n",
      "Epoch 15/500\n",
      "359/359 [==============================] - 301s 838ms/step - loss: 0.5913 - accuracy: 0.8197 - val_loss: 1.0827 - val_accuracy: 0.7305\n",
      "Epoch 16/500\n",
      "359/359 [==============================] - 302s 841ms/step - loss: 0.5294 - accuracy: 0.8388 - val_loss: 1.0854 - val_accuracy: 0.7372\n",
      "Epoch 17/500\n",
      "359/359 [==============================] - 300s 836ms/step - loss: 0.5015 - accuracy: 0.8481 - val_loss: 1.0060 - val_accuracy: 0.7557\n",
      "Epoch 18/500\n",
      "359/359 [==============================] - 299s 833ms/step - loss: 0.5121 - accuracy: 0.8436 - val_loss: 1.1101 - val_accuracy: 0.7372\n",
      "Epoch 19/500\n",
      "359/359 [==============================] - 301s 837ms/step - loss: 0.4741 - accuracy: 0.8579 - val_loss: 1.0483 - val_accuracy: 0.7546\n",
      "Epoch 20/500\n",
      "359/359 [==============================] - 302s 841ms/step - loss: 0.4302 - accuracy: 0.8704 - val_loss: 1.1787 - val_accuracy: 0.7244\n",
      "Epoch 21/500\n",
      "359/359 [==============================] - 300s 836ms/step - loss: 0.4073 - accuracy: 0.8760 - val_loss: 1.0079 - val_accuracy: 0.7543\n",
      "Epoch 22/500\n",
      "359/359 [==============================] - 301s 839ms/step - loss: 0.3897 - accuracy: 0.8812 - val_loss: 1.0127 - val_accuracy: 0.7635\n"
     ]
    }
   ],
   "source": [
    "#fit model - fit on train_generator (both X and y) and the validation data is validation_generator\n",
    "history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch = train_generator.samples // batch_size,\n",
    "                validation_data = validation_generator, \n",
    "                validation_steps = validation_generator.samples // batch_size,\n",
    "                epochs=500,\n",
    "                callbacks=[es],\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa8a460-0ed4-41a6-945f-8a2524c4b83c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ec46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    #ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    #ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "699a582b-3e9d-4e3a-a5cb-d4400a3ef4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e0d1564-881c-4316-8ad9-6f03257a9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_final.h5\", save_format = \"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d008d446-e66b-4bfc-bb5f-b12681a9d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb360ab5-07b1-4052-92cc-51042c93fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(\"model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f08cd40-a797-4bd7-8d07-2cb403b25ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet169 (Functional)    (None, 8, 8, 1664)        12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 106496)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 106496)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              106497000 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 900)               900900    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 900)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 800)               720800    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 700)               560700    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 83)                58183     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,380,463\n",
      "Trainable params: 121,222,063\n",
      "Non-trainable params: 158,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81657d47-147b-43a7-9de7-fc3b19ab9e2a",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31137fc7-c412-4615-ba16-f943c22aa4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2692b-6da9-4646-90bb-10639ac112da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255) # set validation split\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                    test_dir,\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    subset='training',\n",
    "                                    keep_aspect_ratio=True,\n",
    "                                    interpolation='bicubic') # set as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6abfa-b391-48d0-a327-56e257fdc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(\"../test/test/IMG_5553.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39272ea4-e13a-4e28-a319-a9ad98de36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = poses[np.argmax(model.predict(test_generator))]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956aa8e-bc9f-4890-b273-136644e97809",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = poses[np.argmax(model.predict(test_generator))]\n",
    "photo_path = f\"../ground_truth/{prediction}.jpeg\"\n",
    "fig = plt.imshow(mpimg.imread(photo_path))\n",
    "plt.title(prediction)\n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc4cc1-2e08-4908-b96f-79dbedbf236e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5136b-7fc9-43f7-ac6e-1bf2179ec842",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../raw_data/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc01566-be42-4066-a6cf-1186f5c53cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255) # set validation split\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                    test_dir,\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    subset='training',\n",
    "                                    keep_aspect_ratio=True,\n",
    "                                    interpolation='bicubic') # set as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371672e-0ed9-4f5e-b85e-24f4a9fce9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82152fcb-8232-49bb-ab1b-52f89e10f6f7",
   "metadata": {},
   "source": [
    "# Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dedd4c-334d-4bbb-8fad-7d64e30c82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(poses)\n",
    "df[\"probability\"] = model.predict(test_generator)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1ca94-0d5b-4d55-bb3b-1232bbc2673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[0]==\"Sitting_pose_1_(normal)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251de23-1824-4183-9a48-5c54881b2efb",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b3ebb-ef9d-4997-9633-e907c7f443b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../saved_models/model_4.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aa5c6-2d00-4a77-badd-aa22f58e3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"../saved_models/model_1.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5fb8b-674a-4513-8e5f-65fe71cf4ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3106",
   "name": "tf2-gpu.2-8.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m103"
  },
  "kernelspec": {
   "display_name": "python3106",
   "language": "python",
   "name": "python3106"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
