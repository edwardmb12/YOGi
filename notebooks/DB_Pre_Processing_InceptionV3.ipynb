{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73faf589",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adccf1c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import utils, optimizers\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbea69",
   "metadata": {},
   "source": [
    "# Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These variables can be changes, excluding train_dir\n",
    "\n",
    "train_dir = \"../raw_data/Training\"\n",
    "img_height, img_width = 256, 256\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be94b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits into train_generator and validation_generator\n",
    "#This bulk uploads the images\n",
    "#Creates target (y) for us!\n",
    "\n",
    "#Play around with the interpolation argument - bicubic, lanczos??? \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    vertical_flip=True,\n",
    "                                    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                    train_dir,\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    subset='training',\n",
    "                                    keep_aspect_ratio=True,\n",
    "                                    interpolation='lanczos') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                                    train_dir, # same directory as training data\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    subset='validation',\n",
    "                                    keep_aspect_ratio=True,\n",
    "                                    interpolation='lanczos') # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f530f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# Model needs building + transfer learning  \n",
    "...\n",
    "def initialize_model():\n",
    "    base_model = inception_v3.InceptionV3(\n",
    "                        include_top=False,\n",
    "                        weights='imagenet',\n",
    "                        input_shape=(img_height, img_width, 3),\n",
    "                        classifier_activation='softmax')\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = models.Sequential([ \n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(500, activation=\"relu\"),\n",
    "        layers.Dense(83, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb61e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63383da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d35456",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636f75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit model - fit on train_generator (both X and y) and the validation data is validation_generator\n",
    "history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch = train_generator.samples // batch_size,\n",
    "                validation_data = validation_generator, \n",
    "                validation_steps = validation_generator.samples // batch_size,\n",
    "                epochs = 2,\n",
    "                callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ec46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    #ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    #ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a245ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = f\"{root_dir}/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255) # set validation split\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                    test_dir,\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    subset='training',\n",
    "                                    keep_aspect_ratio=True,\n",
    "                                    interpolation='lanczos') # set as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a49c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784a400",
   "metadata": {},
   "source": [
    "# Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This has been paused and probably won't be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(f\"{file_path}/{file_list[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Image\n",
    "image = cv2.imread(f\"{file_path}/{file_list[3]}\")\n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "(humans, _) = hog.detectMultiScale(image, winStride=(3,3),\n",
    "                                padding=(32, 32), \n",
    "                               scale=1.01)\n",
    "\n",
    "# getting no. of human detected\n",
    "print('Human Detected : ', len(humans))\n",
    "\n",
    "# loop over all detected humans\n",
    "for (x, y, w, h) in humans:\n",
    "   pad_w, pad_h = int(0.15 * w), int(0.01 * h)\n",
    "   cv2.rectangle(image, (x + pad_w, y + pad_h), (x + w - pad_w, y + h - pad_h), (0, 255, 0), 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(25)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07339aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170031fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"{file_path}/{file_list[3]}\"\n",
    "photo = cv2.imread(filepath)\n",
    "photo_grey = cv2.cvtColor(photo, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06134bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the HOG person\n",
    "# detector\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "   \n",
    "# Reading the Image\n",
    "image = cv2.imread(filepath)\n",
    "   \n",
    "# Detecting all the regions in the \n",
    "# Image that has a pedestrians inside it\n",
    "(regions, _) = hog.detectMultiScale(image, \n",
    "                                    winStride=(8, 8),\n",
    "                                    padding=(16, 16),\n",
    "                                    scale=1.15)\n",
    "   \n",
    "# Drawing the regions in the Image\n",
    "for (x, y, w, h) in regions:\n",
    "    cv2.rectangle(image, (x, y), \n",
    "                  (x + w, y + h), \n",
    "                  (0, 0, 255), 2)\n",
    "    \n",
    "#Showing the output Image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "   \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
